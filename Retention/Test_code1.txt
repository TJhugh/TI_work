# Get the data 
import pandas as pd
filename='TI_TM10 back up.xlsx'
sheet='Sheet4'
Main_data = pd.read_excel(filename,sheetname=sheet,header=0)

#Main_data.head()
#Main_data.shape 
#Main_data['Status'].value_counts()

# Split the data into Training and Test set
from sklearn.cross_validation import train_test_split
Main_data_train, Main_data_test = train_test_split(Main_data,test_size=0.25)

Split_train= Main_data_train['Status'].value_counts()
Split_test= Main_data_test['Status'].value_counts()

from __future__ import division
split1 = Split_train[1]/(Split_train[1]+Split_train[0])
split2 = Split_test[1]/(Split_test[1]+Split_test[0])

# Get features and labels
import numpy as np
y = Main_data_train[["Status"]]
y_train=np.ravel(y)
y_train.shape 

#colsToDrop = ['Emplid','Name','Team','Status']
#X_train = Main_data_train.drop(colsToDrop, axis=1)
X_train = Main_data_train[['Pos_Tenure','Age']]
#X_train = X_train.as_matrix(columns=None)
#X_train.head()
#X_train.shape 

y2 = Main_data_test[["Status"]]
y_test=np.ravel(y2)

#X_test = Main_data_test.drop(colsToDrop, axis=1)
X_test = Main_data_test[['Pos_Tenure','Age']]
#X_test = X_test.as_matrix(columns=None)

#EDA NOTES
#Age and tenure are correlated
#Hike and score are correlated

# Dimensionality reduction (by feature selection) and Extratreeclassifier
#Pipeline implementation
from sklearn.svm import LinearSVC
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.pipeline import Pipeline
clf = Pipeline([('feature_selection', LinearSVC(penalty="l1")),('classification', ExtraTreesClassifier())])

clf=ExtraTreesClassifier()
clf.fit(X_train,y_train)
y_pred= clf.predict(X_test)

#cross validation 
from sklearn.metrics import mean_squared_error
from sklearn.cross_validation import cross_val_score
roc_auc=cross_val_score(rf,x,y,cv=10,scoring="roc_auc")

accuracy= mean_squared_error(y_test,y_pred)
accuracy

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=5)
#n_neighbors=1
knn.fit(X_train,y_train)
y_pred= knn.predict(X_test)

from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression()
logreg.fit(X_train,y_train)
y_pred= logreg.predict(X_test)

from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=6)
z= kmeans.fit_predict(X_train,y=None)
z.shape
type(X_train)

Main_data_train1 = Main_data_train.as_matrix(columns=None)
np.hstack((Main_data_train1,z))
Main_data_train1.shape
z.shape
jy=pd.DataFrame(z)
type(jy)
jy.info()
jy.head()

df1= pd.concat([X_train,jy],axis=1)
df1.info()
X_train.head()



